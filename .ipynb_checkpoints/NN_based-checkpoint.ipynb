{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import string\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseData(file, read_limit):\n",
    "    null = None\n",
    "    with open(file, errors='ignore') as f:\n",
    "        i=0\n",
    "        for l in f:\n",
    "            if i<read_limit:\n",
    "                i+=1\n",
    "                x = eval(l)\n",
    "                yield x\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "def LoadData(f, read_limit = 100000):\n",
    "    return list(parseData(f, read_limit))\n",
    "\n",
    "business_data = LoadData('yelp_academic_dataset_business.json')\n",
    "review_data = LoadData('yelp_academic_dataset_review.json')\n",
    "tip_data = LoadData('yelp_academic_dataset_tip.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_dict = defaultdict(int)\n",
    "biz_cat_map = defaultdict(list)\n",
    "for data in business_data:\n",
    "    if data['categories'] != None:\n",
    "        biz_cat_map[data['business_id']] = data['categories']\n",
    "        for cat  in data['categories']:\n",
    "            cat_dict[cat]+=1\n",
    "            \n",
    "#years = [d['date'].split('-')[0] for d in data]\n",
    "#data[0]['date'].split('-')[0]\n",
    "sort_cat =  sorted(cat_dict.items(), key=lambda x:x[1])[-50:]\n",
    "sort_cat.reverse()\n",
    "sorted_cat = [d[0] for d in sort_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "said told didn went asked called day came minutes took wanted phone left later wasn\n",
      "Topic #1:\n",
      "und die der das ist ich sehr nicht auch es mit war ein zu man\n",
      "Topic #2:\n",
      "food fast eat mexican atmosphere chinese fresh quality service bad authentic wait delicious eating portions\n",
      "Topic #3:\n",
      "great atmosphere awesome experience fun selection thanks deal spot definitely loved friends variety music family\n",
      "Topic #4:\n",
      "store items selection stores shopping buy clothing sales clothes shoes products grocery helpful sale stuff\n",
      "Topic #5:\n",
      "service customer excellent worst rude slow horrible friendly fast poor manager terrible quick received product\n",
      "Topic #6:\n",
      "et le la est pour les une des en pas que dÃ£ plus es ambiance\n",
      "Topic #7:\n",
      "hair cut salon stylist haircut color style appointment wanted look does products looking doing want\n",
      "Topic #8:\n",
      "dr office dentist care doctor pain patient appointment treatment insurance staff feel visit health wonderful\n",
      "Topic #9:\n",
      "good pretty selection bad value overall tried price thing service ok quite beer decent wings\n",
      "Topic #10:\n",
      "place closed try awesome looking cheap owner want stars eat clean places open sushi live\n",
      "Topic #11:\n",
      "restaurant menu ordered dishes soup dish meal dinner rice fish thai chinese pho sushi beef\n",
      "Topic #12:\n",
      "staff friendly helpful super clean knowledgeable extremely selection welcoming professional attentive easy wonderful wait definitely\n",
      "Topic #13:\n",
      "coffee cafe cup breakfast tea free morning milk drink baked delicious sandwiches chocolate cake hot\n",
      "Topic #14:\n",
      "pizza wings toppings delivery sauce cheese garlic italian pasta ordered large ingredients style chain eat\n",
      "Topic #15:\n",
      "love awesome absolutely fun favorite wonderful super cute feel sweet coming perfect beautiful local clothes\n",
      "Topic #16:\n",
      "little area people lot pretty bit small parking kids park big fun free come definitely\n",
      "Topic #17:\n",
      "bar drinks night beer drink music crowd pub dance bars club wine beers atmosphere sports\n",
      "Topic #18:\n",
      "like feel looks felt look tasted looked didn places taste doesn things thing say old\n",
      "Topic #19:\n",
      "chicken fried rice sauce spicy wings beef pork ordered hot curry salad fries bbq flavor\n",
      "Topic #20:\n",
      "location closed locations convenient clean drive employees open mall busy near fast close easy particular\n",
      "Topic #21:\n",
      "time long wait took second takes times come waste visit definitely appointment experience hour spent\n",
      "Topic #22:\n",
      "really liked enjoyed think cool cheap wanted didn wasn bad knows say awesome impressed going\n",
      "Topic #23:\n",
      "car wash repair oil drive gas fixed parts took insurance guys change needed guy station\n",
      "Topic #24:\n",
      "need help use needed come ll ask honest fix knowledgeable way home stuff looking check\n",
      "Topic #25:\n",
      "ice cream chocolate flavors cake sweet yogurt flavor butter cupcakes frozen dessert tea cookies water\n",
      "Topic #26:\n",
      "best town far vegas hands city las life experience probably awesome thing charlotte thanks gem\n",
      "Topic #27:\n",
      "ve times seen tried gone ll far twice worst gotten say eaten past couple bad\n",
      "Topic #28:\n",
      "just say maybe ok right want wish ll thing wanted think bad way try doesn\n",
      "Topic #29:\n",
      "nice clean super atmosphere decor inside quiet patio pleasant lots touch ambiance owner outside people\n",
      "Topic #30:\n",
      "company business owner money home pool use phone called house insurance professional run months website\n",
      "Topic #31:\n",
      "dog dogs park hot owners care walk walking run area play owner city taking bring\n",
      "Topic #32:\n",
      "recommend highly professional recommended definitely excellent knowledgeable wonderful friends looking services experience family extremely care\n",
      "Topic #33:\n",
      "don know want think people care let expect money ll buy ask waste come doesn\n",
      "Topic #34:\n",
      "amazing wedding loved thank wonderful beautiful absolutely perfect chocolate definitely delicious cake cupcakes look super\n",
      "Topic #35:\n",
      "work professional quality guys home team wedding easy people working does thank worked hard honest\n",
      "Topic #36:\n",
      "room hotel stay breakfast clean rooms pool stayed bed night desk bathroom comfortable floor free\n",
      "Topic #37:\n",
      "new brand old home owner try management thanks owners year favorite recently moved looking looks\n",
      "Topic #38:\n",
      "lunch breakfast quick soup sandwiches menu dinner salad specials sandwich spot cafe special today day\n",
      "Topic #39:\n",
      "prices reasonable quality price high selection items fair stores low products cheap decent worth produce\n",
      "Topic #40:\n",
      "better places way ok far think average price gets quality cheaper say expected maybe overpriced\n",
      "Topic #41:\n",
      "did job does nails cleaning professional fantastic glad nail house clean use wonderful look came\n",
      "Topic #42:\n",
      "cheese fresh sandwich bread fries delicious salad burger sauce sandwiches meat tasty bacon ordered grilled\n",
      "Topic #43:\n",
      "shop bike shops local gift buy selection owner products items repair stock little unique helpful\n",
      "Topic #44:\n",
      "order delivery ordered minutes wait wrong orders fries online ordering drive drink hot pick waiting\n",
      "Topic #45:\n",
      "make sure feel happy ll want stop making look right makes appointment know wedding check\n",
      "Topic #46:\n",
      "class classes yoga studio gym fun students hot feel different body offer week community equipment\n",
      "Topic #47:\n",
      "got went deal groupon finally wasn definitely loved friend right today happy home used came\n",
      "Topic #48:\n",
      "massage nails spa nail salon body professional treatment appointment pain skin services feet feel groupon\n",
      "Topic #49:\n",
      "years going ago family coming year past used old moved couple 10 changed school 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 15\n",
    "n_feat = 1500\n",
    "n_topics = 50\n",
    "\n",
    "topic_words = defaultdict(list)\n",
    "topic_group = defaultdict(list)\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        for i in topic.argsort()[:-n_top_words - 1:-1]:\n",
    "            #print(feature_names[i])\n",
    "            topic_words[topic_idx].append(feature_names[i])\n",
    "            topic_group[feature_names[i]].append(topic_idx)\n",
    "        \n",
    "    print()\n",
    "\n",
    "train = int(len(review_data)/2)\n",
    "corpus = [d['text'] for d in review_data[train:] if len(biz_cat_map[d['business_id']])> 0]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english', max_df=0.95, min_df=2)\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "nmf = NMF(n_components=n_topics, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def divide_shuffle(X, Y_cat):\n",
    "    X, Y = shuffle(X, Y_cat, random_state=0)\n",
    "    train = int(len(X)/2)\n",
    "    X_train = X[:train]\n",
    "    Y_train = Y[:train]\n",
    "    X_test = X[train:]\n",
    "    Y_test = Y[train:]\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "wordCount = defaultdict(int)\n",
    "bigramCount = defaultdict(int)\n",
    "\n",
    "def parse(review):\n",
    "    return ''.join([c for c in review.lower() if not c in punctuation])\n",
    "    \n",
    "def process(review):\n",
    "    r = parse(review)\n",
    "    words = r.split()\n",
    "    for w in words:\n",
    "        wordCount[w]+=1\n",
    "    for i in range(len(words) - 1):\n",
    "        bigramCount[(words[i], words[i+1])]+=1\n",
    "    return r;\n",
    "\n",
    "def get_group_member_vector(review):\n",
    "    feat = [0]*n_topics\n",
    "    r = parse(review)\n",
    "    words = r.split()\n",
    "    for word in words:\n",
    "        indices = topic_group[word]\n",
    "        for index in indices:\n",
    "            feat[index]+=1\n",
    "    return feat;\n",
    "\n",
    "Y_cat_allhot=[]\n",
    "for data in review_data:\n",
    "    biz_id = data['business_id']\n",
    "    biz_cat = biz_cat_map[biz_id]\n",
    "    Y_re = []\n",
    "    if len(biz_cat) > 0: \n",
    "        for i in range(len(sort_cat)):\n",
    "            if sorted_cat[i] in biz_cat:\n",
    "                Y_re.append(i)\n",
    "        Y_cat_allhot.append(Y_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = [get_group_member_vector(d['text']) for d in review_data if len(biz_cat_map[d['business_id']])>0]\n",
    "X_train, Y_train, X_test, Y_test = divide_shuffle(X, Y_cat_allhot)\n",
    "\n",
    "Y_train = MultiLabelBinarizer().fit_transform(Y_train)\n",
    "Y_test = MultiLabelBinarizer().fit_transform(Y_test)\n",
    "\n",
    "Y_normlizer = np.sum(Y_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(X_train)\n",
    "X_new_train = pca.transform(X_train)\n",
    "X_new_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RadiusNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, outlier_label=None, p=2, radius=4,\n",
       "             weights='distance')"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = neighbors.RadiusNeighborsClassifier(radius=4, weights='distance')\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"training score : %.3f (%s)\" % (clf.score(X_train, Y_train), 'multinomial'))\n",
    "#print(\"training score : %.3f (%s)\" % (clf.score(X_test, Y_test), 'multinomial'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lin = neighbors.KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "clf_lin.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:8997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3875988864568731"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_loss(clf, X, Y):\n",
    "    res = 0.0\n",
    "    print (\"total:\" + str(len(X)))\n",
    "    for i in range(len(X)):\n",
    "        nn_idx = clf.radius_neighbors([X[i]], return_distance=False)[0]\n",
    "        y_pred = (np.sum([Y_test[i] for i in nn_idx], axis=0)> len(nn_idx)/2)*1\n",
    "        #y_pred = clf.predict([X[i]])\n",
    "        res+=(np.linalg.norm(y_pred-Y[i]))\n",
    "    return res/len(Y)\n",
    "calc_loss(clf, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:8997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3796330565736359"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_loss(clf, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurants\n",
      "Nightlife\n",
      "Bars\n",
      "American (Traditional)\n"
     ]
    }
   ],
   "source": [
    "for i in Y_cat_allhot[0]:\n",
    "    print(sorted_cat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nightlife', 'American (Traditional)', 'Pubs', 'Restaurants', 'Bars']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz_cat_map[X_biz_id[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_biz_id = [(d['business_id']) for d in review_data if len(biz_cat_map[d['business_id']])>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_idx = clf.radius_neighbors([X_train[0]], return_distance=False)[0]\n",
    "y_pred = (np.sum([Y_train[i] for i in nn_idx], axis=0)> len(nn_idx)/10)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([676, 115, 257,  37,  28,  44, 138, 122,  17,  22,  42,  49,  38,\n",
       "        36,  63,  48,  33,  66,  13,  38,  42, 102,   9,   2,  30,  47,\n",
       "        12,  15,   2,  22,  19,   8,  47,   9,   6,  14,  26,  34,  68,\n",
       "         9,  30,   2,  16,  26,   4,   6,  28,   5,   4,   3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(t, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurants\n",
      "Food\n",
      "Nightlife\n",
      "Bars\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == 1:\n",
    "        print(sorted_cat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28820"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_cat = np.array(sorted_cat)\n",
    "miss_cat = defaultdict(int)\n",
    "\n",
    "def calc_loss(clf, X, T, Y_train, radius = 4, distance_factor=10):\n",
    "    miss_count=0\n",
    "    miss_business = 0\n",
    "    all_real=0\n",
    "    #print (\"total:\" + str(len(X)))\n",
    "    for i in range(len(X)):\n",
    "        nn_idx = []\n",
    "        nn_idx = clf.kneighbors([X[i]], return_distance=False)[0]\n",
    "        temp_radius = radius\n",
    "        #while len(nn_idx) <= 10 :\n",
    "        #    nn_idx = clf.radius_neighbors([X[i]], radius=temp_radius, return_distance=False)[0]\n",
    "        #    temp_radius += 0.5\n",
    "        #print(len(nn_idx))\n",
    "        y_pred = (np.sum([Y_train[i] for i in nn_idx], axis=0)> len(nn_idx)/distance_factor)*1\n",
    "        #y_pred = clf.predict([X[i]])[0]\n",
    "        #print (y_pred)\n",
    "        T_cat = [j for j in range(len(T[i])) if T[i][j] == 1]\n",
    "        Y_cat = [j for j in range(len(y_pred)) if y_pred[j] == 1]\n",
    "        tagged = False\n",
    "        for real_cat in T_cat:\n",
    "            all_real+=1\n",
    "            if real_cat not in Y_cat:\n",
    "                miss_count+=1\n",
    "                miss_cat[real_cat] += 1\n",
    "            else\n",
    "                tagged = True\n",
    "        if not tagged:\n",
    "            miss_business+=1;\n",
    "        #print (\"Real:\", sorted_cat[T_cat])\n",
    "        #print (\"Predicted:\", sorted_cat[Y_cat])\n",
    "    return miss_count\n",
    "    #return res/len(Y)\n",
    "calc_loss(clf_lin, X_test, Y_test, Y_train, 2, 10)\n",
    "#calc_loss(clf, X_test[170:180], Y_test[170:180], Y_train, 2, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurants 361\n",
      "Shopping 814\n",
      "Food 1171\n",
      "Beauty & Spas 782\n",
      "Home Services 605\n",
      "Nightlife 1016\n",
      "Health & Medical 542\n",
      "Bars 966\n",
      "Automotive 584\n",
      "Local Services 804\n",
      "Event Planning & Services 1059\n",
      "Active Life 771\n",
      "Fashion 583\n",
      "American (Traditional) 813\n",
      "Pizza 547\n",
      "Fast Food 746\n",
      "Sandwiches 717\n",
      "Coffee & Tea 915\n",
      "Arts & Entertainment 926\n",
      "Hair Salons 338\n",
      "Hotels & Travel 622\n",
      "Italian 771\n",
      "Home & Garden 567\n",
      "Auto Repair 300\n",
      "Burgers 669\n",
      "Mexican 593\n",
      "Chinese 507\n",
      "American (New) 735\n",
      "Doctors 261\n",
      "Breakfast & Brunch 598\n",
      "Nail Salons 317\n",
      "Real Estate 393\n",
      "Specialty Food 716\n",
      "Fitness & Instruction 367\n",
      "Professional Services 411\n",
      "Pets 392\n",
      "Grocery 647\n",
      "Bakeries 571\n",
      "Cafes 573\n",
      "Dentists 121\n",
      "Hotels 266\n",
      "Hair Removal 338\n",
      "Women's Clothing 398\n",
      "Desserts 387\n",
      "Skin Care 379\n",
      "Japanese 414\n",
      "Ice Cream & Frozen Yogurt 388\n",
      "Day Spas 282\n",
      "Pet Services 283\n",
      "Pubs 494\n"
     ]
    }
   ],
   "source": [
    "for miss in miss_cat:\n",
    "    print (sorted_cat[miss], miss_cat[miss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = clf.predict([X_train[1]])[0]\n",
    "pred\n",
    "pred_cat = [j for j in range(len(pred)) if pred[j] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ array([1273,   99, 1140, 3077, 4443,  735, 4761, 4714, 6285, 6972, 7593,\n",
      "       7966, 8253], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "nn_idx = clf.radius_neighbors([X_train[1140]], return_distance=False)\n",
    "print (nn_idx)\n",
    "y_pred = np.sum([Y_train[i] for i in nn_idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
